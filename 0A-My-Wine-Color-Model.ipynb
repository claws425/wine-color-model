{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEPLOYMENT\n",
    "\n",
    "**Welcome to deployment section! In this section of the course, we will go through the entire deployment process, starting as if you had to create a servicable model from scratch, then deploy it for others to use, either through API or a web form.**\n",
    "\n",
    "# Data\n",
    "\n",
    "For this example we use the wine quality data set: [wine dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/), which is about the quality of red and white wine. \n",
    "\n",
    "From UCI Machine Learning:\n",
    "The two datasets are related to red and white variants of the Portuguese \"Vinho Verde\" wine.\n",
    "\n",
    "The data set consists of over 6,000 combines samples of white and red wine. 13 features were measured from each sample: fixed acidity, volatile acidity, citric acide, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates, alcohol, quality, and color. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = pd.read_csv(\"data/winedata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  color  \n",
       "0      8.8        6  white  \n",
       "1      9.5        6  white  \n",
       "2     10.1        6  white  \n",
       "3      9.9        6  white  \n",
       "4      9.9        6  white  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
       "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
       "       'pH', 'sulphates', 'alcohol', 'quality', 'color'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wine.drop('color',axis=1)\n",
    "y = wine['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['white', 'red'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine['color'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lots of ways to one hot encode\n",
    "# https://stackoverflow.com/questions/47573293/unable-to-transform-string-column-to-categorical-matrix-using-keras-and-sklearn\n",
    "# https://stackoverflow.com/questions/35107559/one-hot-encoding-of-string-categorical-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()\n",
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "\n",
    "### Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=12,activation='relu',input_shape=[12,]))\n",
    "\n",
    "# Last layer for multi-class classification of 2 colors\n",
    "model.add(Dense(units=2,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5197 samples, validate on 1300 samples\n",
      "Epoch 1/300\n",
      "5197/5197 [==============================] - 1s 99us/sample - loss: 0.5545 - accuracy: 0.7377 - val_loss: 0.4493 - val_accuracy: 0.7654\n",
      "Epoch 2/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.3740 - accuracy: 0.8297 - val_loss: 0.2926 - val_accuracy: 0.8923\n",
      "Epoch 3/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.2323 - accuracy: 0.9486 - val_loss: 0.1802 - val_accuracy: 0.9623\n",
      "Epoch 4/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.1485 - accuracy: 0.9754 - val_loss: 0.1253 - val_accuracy: 0.9746\n",
      "Epoch 5/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.1105 - accuracy: 0.9792 - val_loss: 0.0973 - val_accuracy: 0.9792\n",
      "Epoch 6/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0906 - accuracy: 0.9823 - val_loss: 0.0814 - val_accuracy: 0.9808\n",
      "Epoch 7/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0790 - accuracy: 0.9821 - val_loss: 0.0711 - val_accuracy: 0.9823\n",
      "Epoch 8/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0715 - accuracy: 0.9825 - val_loss: 0.0639 - val_accuracy: 0.9854\n",
      "Epoch 9/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0659 - accuracy: 0.9836 - val_loss: 0.0588 - val_accuracy: 0.9846\n",
      "Epoch 10/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0618 - accuracy: 0.9844 - val_loss: 0.0559 - val_accuracy: 0.9846\n",
      "Epoch 11/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0588 - accuracy: 0.9852 - val_loss: 0.0515 - val_accuracy: 0.9877\n",
      "Epoch 12/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0563 - accuracy: 0.9863 - val_loss: 0.0491 - val_accuracy: 0.9862\n",
      "Epoch 13/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0543 - accuracy: 0.9854 - val_loss: 0.0479 - val_accuracy: 0.9862\n",
      "Epoch 14/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0527 - accuracy: 0.9867 - val_loss: 0.0451 - val_accuracy: 0.9885\n",
      "Epoch 15/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0513 - accuracy: 0.9869 - val_loss: 0.0435 - val_accuracy: 0.9885\n",
      "Epoch 16/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0500 - accuracy: 0.9871 - val_loss: 0.0425 - val_accuracy: 0.9892\n",
      "Epoch 17/300\n",
      "5197/5197 [==============================] - 0s 38us/sample - loss: 0.0489 - accuracy: 0.9883 - val_loss: 0.0414 - val_accuracy: 0.9892\n",
      "Epoch 18/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0479 - accuracy: 0.9881 - val_loss: 0.0403 - val_accuracy: 0.9908\n",
      "Epoch 19/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0473 - accuracy: 0.9879 - val_loss: 0.0395 - val_accuracy: 0.9900\n",
      "Epoch 20/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0460 - accuracy: 0.9885 - val_loss: 0.0392 - val_accuracy: 0.9885\n",
      "Epoch 21/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0455 - accuracy: 0.9879 - val_loss: 0.0386 - val_accuracy: 0.9900\n",
      "Epoch 22/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0450 - accuracy: 0.9888 - val_loss: 0.0386 - val_accuracy: 0.9908\n",
      "Epoch 23/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0444 - accuracy: 0.9879 - val_loss: 0.0367 - val_accuracy: 0.9915\n",
      "Epoch 24/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0437 - accuracy: 0.9883 - val_loss: 0.0361 - val_accuracy: 0.9915\n",
      "Epoch 25/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0430 - accuracy: 0.9890 - val_loss: 0.0367 - val_accuracy: 0.9908\n",
      "Epoch 26/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0425 - accuracy: 0.9890 - val_loss: 0.0358 - val_accuracy: 0.9908\n",
      "Epoch 27/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0419 - accuracy: 0.9890 - val_loss: 0.0350 - val_accuracy: 0.9915\n",
      "Epoch 28/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0421 - accuracy: 0.9892 - val_loss: 0.0348 - val_accuracy: 0.9908\n",
      "Epoch 29/300\n",
      "5197/5197 [==============================] - 0s 39us/sample - loss: 0.0413 - accuracy: 0.9888 - val_loss: 0.0343 - val_accuracy: 0.9908\n",
      "Epoch 30/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0408 - accuracy: 0.9888 - val_loss: 0.0338 - val_accuracy: 0.9923\n",
      "Epoch 31/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0402 - accuracy: 0.9890 - val_loss: 0.0348 - val_accuracy: 0.9908\n",
      "Epoch 32/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0401 - accuracy: 0.9896 - val_loss: 0.0332 - val_accuracy: 0.9923\n",
      "Epoch 33/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0398 - accuracy: 0.9894 - val_loss: 0.0328 - val_accuracy: 0.9923\n",
      "Epoch 34/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0394 - accuracy: 0.9896 - val_loss: 0.0337 - val_accuracy: 0.9908\n",
      "Epoch 35/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0387 - accuracy: 0.9902 - val_loss: 0.0333 - val_accuracy: 0.9908\n",
      "Epoch 36/300\n",
      "5197/5197 [==============================] - 0s 38us/sample - loss: 0.0388 - accuracy: 0.9892 - val_loss: 0.0321 - val_accuracy: 0.9923\n",
      "Epoch 37/300\n",
      "5197/5197 [==============================] - 0s 38us/sample - loss: 0.0384 - accuracy: 0.9900 - val_loss: 0.0319 - val_accuracy: 0.9923\n",
      "Epoch 38/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0379 - accuracy: 0.9902 - val_loss: 0.0316 - val_accuracy: 0.9923\n",
      "Epoch 39/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0378 - accuracy: 0.9902 - val_loss: 0.0315 - val_accuracy: 0.9923\n",
      "Epoch 40/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0376 - accuracy: 0.9906 - val_loss: 0.0318 - val_accuracy: 0.9908\n",
      "Epoch 41/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0372 - accuracy: 0.9902 - val_loss: 0.0312 - val_accuracy: 0.9923\n",
      "Epoch 42/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0368 - accuracy: 0.9910 - val_loss: 0.0311 - val_accuracy: 0.9923\n",
      "Epoch 43/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0366 - accuracy: 0.9908 - val_loss: 0.0308 - val_accuracy: 0.9915\n",
      "Epoch 44/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0366 - accuracy: 0.9902 - val_loss: 0.0306 - val_accuracy: 0.9923\n",
      "Epoch 45/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0363 - accuracy: 0.9900 - val_loss: 0.0305 - val_accuracy: 0.9923\n",
      "Epoch 46/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0363 - accuracy: 0.9906 - val_loss: 0.0303 - val_accuracy: 0.9915\n",
      "Epoch 47/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0356 - accuracy: 0.9904 - val_loss: 0.0303 - val_accuracy: 0.9923\n",
      "Epoch 48/300\n",
      "5197/5197 [==============================] - 0s 38us/sample - loss: 0.0356 - accuracy: 0.9910 - val_loss: 0.0299 - val_accuracy: 0.9923\n",
      "Epoch 49/300\n",
      "5197/5197 [==============================] - 0s 38us/sample - loss: 0.0355 - accuracy: 0.9913 - val_loss: 0.0308 - val_accuracy: 0.9908\n",
      "Epoch 50/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0353 - accuracy: 0.9908 - val_loss: 0.0298 - val_accuracy: 0.9915\n",
      "Epoch 51/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0351 - accuracy: 0.9908 - val_loss: 0.0298 - val_accuracy: 0.9915\n",
      "Epoch 52/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0348 - accuracy: 0.9915 - val_loss: 0.0295 - val_accuracy: 0.9915\n",
      "Epoch 53/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0346 - accuracy: 0.9906 - val_loss: 0.0297 - val_accuracy: 0.9923\n",
      "Epoch 54/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0347 - accuracy: 0.9906 - val_loss: 0.0306 - val_accuracy: 0.9908\n",
      "Epoch 55/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0344 - accuracy: 0.9908 - val_loss: 0.0293 - val_accuracy: 0.9915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/300\n",
      "5197/5197 [==============================] - 0s 38us/sample - loss: 0.0341 - accuracy: 0.9911 - val_loss: 0.0290 - val_accuracy: 0.9923\n",
      "Epoch 57/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0339 - accuracy: 0.9908 - val_loss: 0.0291 - val_accuracy: 0.9915\n",
      "Epoch 58/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0340 - accuracy: 0.9911 - val_loss: 0.0304 - val_accuracy: 0.9908\n",
      "Epoch 59/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0338 - accuracy: 0.9911 - val_loss: 0.0285 - val_accuracy: 0.9923\n",
      "Epoch 60/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0334 - accuracy: 0.9913 - val_loss: 0.0283 - val_accuracy: 0.9923\n",
      "Epoch 61/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0333 - accuracy: 0.9911 - val_loss: 0.0287 - val_accuracy: 0.9923\n",
      "Epoch 62/300\n",
      "5197/5197 [==============================] - 0s 39us/sample - loss: 0.0333 - accuracy: 0.9908 - val_loss: 0.0292 - val_accuracy: 0.9923\n",
      "Epoch 63/300\n",
      "5197/5197 [==============================] - 0s 41us/sample - loss: 0.0330 - accuracy: 0.9911 - val_loss: 0.0281 - val_accuracy: 0.9923\n",
      "Epoch 64/300\n",
      "5197/5197 [==============================] - 0s 40us/sample - loss: 0.0329 - accuracy: 0.9919 - val_loss: 0.0280 - val_accuracy: 0.9938\n",
      "Epoch 65/300\n",
      "5197/5197 [==============================] - 0s 41us/sample - loss: 0.0328 - accuracy: 0.9917 - val_loss: 0.0278 - val_accuracy: 0.9923\n",
      "Epoch 66/300\n",
      "5197/5197 [==============================] - 0s 41us/sample - loss: 0.0327 - accuracy: 0.9917 - val_loss: 0.0277 - val_accuracy: 0.9923\n",
      "Epoch 67/300\n",
      "5197/5197 [==============================] - 0s 41us/sample - loss: 0.0325 - accuracy: 0.9910 - val_loss: 0.0277 - val_accuracy: 0.9923\n",
      "Epoch 68/300\n",
      "5197/5197 [==============================] - 0s 41us/sample - loss: 0.0325 - accuracy: 0.9911 - val_loss: 0.0275 - val_accuracy: 0.9923\n",
      "Epoch 69/300\n",
      "5197/5197 [==============================] - 0s 41us/sample - loss: 0.0321 - accuracy: 0.9915 - val_loss: 0.0276 - val_accuracy: 0.9923\n",
      "Epoch 70/300\n",
      "5197/5197 [==============================] - 0s 43us/sample - loss: 0.0320 - accuracy: 0.9917 - val_loss: 0.0279 - val_accuracy: 0.9923\n",
      "Epoch 71/300\n",
      "5197/5197 [==============================] - 0s 40us/sample - loss: 0.0317 - accuracy: 0.9910 - val_loss: 0.0272 - val_accuracy: 0.9923\n",
      "Epoch 72/300\n",
      "5197/5197 [==============================] - 0s 41us/sample - loss: 0.0318 - accuracy: 0.9917 - val_loss: 0.0275 - val_accuracy: 0.9923\n",
      "Epoch 73/300\n",
      "5197/5197 [==============================] - 0s 40us/sample - loss: 0.0314 - accuracy: 0.9919 - val_loss: 0.0273 - val_accuracy: 0.9923\n",
      "Epoch 74/300\n",
      "5197/5197 [==============================] - 0s 40us/sample - loss: 0.0315 - accuracy: 0.9917 - val_loss: 0.0269 - val_accuracy: 0.9923\n",
      "Epoch 75/300\n",
      "5197/5197 [==============================] - 0s 39us/sample - loss: 0.0313 - accuracy: 0.9921 - val_loss: 0.0269 - val_accuracy: 0.9931\n",
      "Epoch 76/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0310 - accuracy: 0.9917 - val_loss: 0.0269 - val_accuracy: 0.9923\n",
      "Epoch 77/300\n",
      "5197/5197 [==============================] - 0s 39us/sample - loss: 0.0311 - accuracy: 0.9910 - val_loss: 0.0269 - val_accuracy: 0.9923\n",
      "Epoch 78/300\n",
      "5197/5197 [==============================] - 0s 41us/sample - loss: 0.0310 - accuracy: 0.9921 - val_loss: 0.0267 - val_accuracy: 0.9931\n",
      "Epoch 79/300\n",
      "5197/5197 [==============================] - 0s 39us/sample - loss: 0.0306 - accuracy: 0.9917 - val_loss: 0.0267 - val_accuracy: 0.9923\n",
      "Epoch 80/300\n",
      "5197/5197 [==============================] - 0s 41us/sample - loss: 0.0305 - accuracy: 0.9921 - val_loss: 0.0266 - val_accuracy: 0.9938\n",
      "Epoch 81/300\n",
      "5197/5197 [==============================] - 0s 44us/sample - loss: 0.0302 - accuracy: 0.9925 - val_loss: 0.0269 - val_accuracy: 0.9923\n",
      "Epoch 82/300\n",
      "5197/5197 [==============================] - 0s 39us/sample - loss: 0.0303 - accuracy: 0.9925 - val_loss: 0.0264 - val_accuracy: 0.9923\n",
      "Epoch 83/300\n",
      "5197/5197 [==============================] - 0s 39us/sample - loss: 0.0298 - accuracy: 0.9917 - val_loss: 0.0262 - val_accuracy: 0.9938\n",
      "Epoch 84/300\n",
      "5197/5197 [==============================] - 0s 32us/sample - loss: 0.0301 - accuracy: 0.9919 - val_loss: 0.0263 - val_accuracy: 0.9923\n",
      "Epoch 85/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0299 - accuracy: 0.9921 - val_loss: 0.0263 - val_accuracy: 0.9923\n",
      "Epoch 86/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0296 - accuracy: 0.9925 - val_loss: 0.0259 - val_accuracy: 0.9931\n",
      "Epoch 87/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0293 - accuracy: 0.9929 - val_loss: 0.0259 - val_accuracy: 0.9923\n",
      "Epoch 88/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0295 - accuracy: 0.9923 - val_loss: 0.0266 - val_accuracy: 0.9915\n",
      "Epoch 89/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0294 - accuracy: 0.9921 - val_loss: 0.0258 - val_accuracy: 0.9923\n",
      "Epoch 90/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0291 - accuracy: 0.9931 - val_loss: 0.0256 - val_accuracy: 0.9946\n",
      "Epoch 91/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0290 - accuracy: 0.9919 - val_loss: 0.0255 - val_accuracy: 0.9946\n",
      "Epoch 92/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0289 - accuracy: 0.9927 - val_loss: 0.0254 - val_accuracy: 0.9946\n",
      "Epoch 93/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0287 - accuracy: 0.9927 - val_loss: 0.0255 - val_accuracy: 0.9931\n",
      "Epoch 94/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0284 - accuracy: 0.9927 - val_loss: 0.0254 - val_accuracy: 0.9931\n",
      "Epoch 95/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0287 - accuracy: 0.9931 - val_loss: 0.0252 - val_accuracy: 0.9946\n",
      "Epoch 96/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0281 - accuracy: 0.9935 - val_loss: 0.0257 - val_accuracy: 0.9923\n",
      "Epoch 97/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0282 - accuracy: 0.9937 - val_loss: 0.0258 - val_accuracy: 0.9931\n",
      "Epoch 98/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0279 - accuracy: 0.9927 - val_loss: 0.0248 - val_accuracy: 0.9931\n",
      "Epoch 99/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0279 - accuracy: 0.9935 - val_loss: 0.0253 - val_accuracy: 0.9923\n",
      "Epoch 100/300\n",
      "5197/5197 [==============================] - 0s 38us/sample - loss: 0.0277 - accuracy: 0.9927 - val_loss: 0.0257 - val_accuracy: 0.9923\n",
      "Epoch 101/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0280 - accuracy: 0.9929 - val_loss: 0.0250 - val_accuracy: 0.9931\n",
      "Epoch 102/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0277 - accuracy: 0.9931 - val_loss: 0.0251 - val_accuracy: 0.9923\n",
      "Epoch 103/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0277 - accuracy: 0.9931 - val_loss: 0.0247 - val_accuracy: 0.9931\n",
      "Epoch 104/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0274 - accuracy: 0.9927 - val_loss: 0.0245 - val_accuracy: 0.9931\n",
      "Epoch 105/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0272 - accuracy: 0.9937 - val_loss: 0.0248 - val_accuracy: 0.9946\n",
      "Epoch 106/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0274 - accuracy: 0.9938 - val_loss: 0.0252 - val_accuracy: 0.9923\n",
      "Epoch 107/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0271 - accuracy: 0.9933 - val_loss: 0.0243 - val_accuracy: 0.9931\n",
      "Epoch 108/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0269 - accuracy: 0.9933 - val_loss: 0.0244 - val_accuracy: 0.9946\n",
      "Epoch 109/300\n",
      "5197/5197 [==============================] - 0s 38us/sample - loss: 0.0266 - accuracy: 0.9935 - val_loss: 0.0242 - val_accuracy: 0.9946\n",
      "Epoch 110/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0267 - accuracy: 0.9937 - val_loss: 0.0245 - val_accuracy: 0.9931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0269 - accuracy: 0.9935 - val_loss: 0.0241 - val_accuracy: 0.9931\n",
      "Epoch 112/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0266 - accuracy: 0.9933 - val_loss: 0.0251 - val_accuracy: 0.9915\n",
      "Epoch 113/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0265 - accuracy: 0.9937 - val_loss: 0.0241 - val_accuracy: 0.9931\n",
      "Epoch 114/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0264 - accuracy: 0.9940 - val_loss: 0.0241 - val_accuracy: 0.9946\n",
      "Epoch 115/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0262 - accuracy: 0.9933 - val_loss: 0.0242 - val_accuracy: 0.9931\n",
      "Epoch 116/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0261 - accuracy: 0.9940 - val_loss: 0.0239 - val_accuracy: 0.9931\n",
      "Epoch 117/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0262 - accuracy: 0.9937 - val_loss: 0.0237 - val_accuracy: 0.9946\n",
      "Epoch 118/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0259 - accuracy: 0.9938 - val_loss: 0.0235 - val_accuracy: 0.9946\n",
      "Epoch 119/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0259 - accuracy: 0.9938 - val_loss: 0.0234 - val_accuracy: 0.9946\n",
      "Epoch 120/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0257 - accuracy: 0.9946 - val_loss: 0.0237 - val_accuracy: 0.9946\n",
      "Epoch 121/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0256 - accuracy: 0.9944 - val_loss: 0.0235 - val_accuracy: 0.9946\n",
      "Epoch 122/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0255 - accuracy: 0.9937 - val_loss: 0.0238 - val_accuracy: 0.9946\n",
      "Epoch 123/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0258 - accuracy: 0.9946 - val_loss: 0.0234 - val_accuracy: 0.9946\n",
      "Epoch 124/300\n",
      "5197/5197 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.99 - 0s 35us/sample - loss: 0.0254 - accuracy: 0.9948 - val_loss: 0.0234 - val_accuracy: 0.9946\n",
      "Epoch 125/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0251 - accuracy: 0.9938 - val_loss: 0.0242 - val_accuracy: 0.9938\n",
      "Epoch 126/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0253 - accuracy: 0.9944 - val_loss: 0.0232 - val_accuracy: 0.9946\n",
      "Epoch 127/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0253 - accuracy: 0.9938 - val_loss: 0.0232 - val_accuracy: 0.9946\n",
      "Epoch 128/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0249 - accuracy: 0.9944 - val_loss: 0.0236 - val_accuracy: 0.9931\n",
      "Epoch 129/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0251 - accuracy: 0.9940 - val_loss: 0.0231 - val_accuracy: 0.9938\n",
      "Epoch 130/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0250 - accuracy: 0.9944 - val_loss: 0.0230 - val_accuracy: 0.9938\n",
      "Epoch 131/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0252 - accuracy: 0.9942 - val_loss: 0.0230 - val_accuracy: 0.9938\n",
      "Epoch 132/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0251 - accuracy: 0.9942 - val_loss: 0.0227 - val_accuracy: 0.9946\n",
      "Epoch 133/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0247 - accuracy: 0.9948 - val_loss: 0.0233 - val_accuracy: 0.9946\n",
      "Epoch 134/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0248 - accuracy: 0.9942 - val_loss: 0.0230 - val_accuracy: 0.9946\n",
      "Epoch 135/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0249 - accuracy: 0.9944 - val_loss: 0.0225 - val_accuracy: 0.9946\n",
      "Epoch 136/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0245 - accuracy: 0.9948 - val_loss: 0.0224 - val_accuracy: 0.9946\n",
      "Epoch 137/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0243 - accuracy: 0.9952 - val_loss: 0.0232 - val_accuracy: 0.9931\n",
      "Epoch 138/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0242 - accuracy: 0.9942 - val_loss: 0.0235 - val_accuracy: 0.9946\n",
      "Epoch 139/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0244 - accuracy: 0.9954 - val_loss: 0.0224 - val_accuracy: 0.9946\n",
      "Epoch 140/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0242 - accuracy: 0.9950 - val_loss: 0.0226 - val_accuracy: 0.9946\n",
      "Epoch 141/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0242 - accuracy: 0.9944 - val_loss: 0.0223 - val_accuracy: 0.9946\n",
      "Epoch 142/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0239 - accuracy: 0.9946 - val_loss: 0.0227 - val_accuracy: 0.9946\n",
      "Epoch 143/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0243 - accuracy: 0.9944 - val_loss: 0.0224 - val_accuracy: 0.9946\n",
      "Epoch 144/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0240 - accuracy: 0.9946 - val_loss: 0.0223 - val_accuracy: 0.9938\n",
      "Epoch 145/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0237 - accuracy: 0.9948 - val_loss: 0.0228 - val_accuracy: 0.9946\n",
      "Epoch 146/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0237 - accuracy: 0.9950 - val_loss: 0.0220 - val_accuracy: 0.9946\n",
      "Epoch 147/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0236 - accuracy: 0.9952 - val_loss: 0.0225 - val_accuracy: 0.9938\n",
      "Epoch 148/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0236 - accuracy: 0.9944 - val_loss: 0.0220 - val_accuracy: 0.9946\n",
      "Epoch 149/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0237 - accuracy: 0.9952 - val_loss: 0.0221 - val_accuracy: 0.9946\n",
      "Epoch 150/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0233 - accuracy: 0.9950 - val_loss: 0.0219 - val_accuracy: 0.9946\n",
      "Epoch 151/300\n",
      "5197/5197 [==============================] - 0s 38us/sample - loss: 0.0234 - accuracy: 0.9952 - val_loss: 0.0230 - val_accuracy: 0.9946\n",
      "Epoch 152/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0232 - accuracy: 0.9948 - val_loss: 0.0230 - val_accuracy: 0.9938\n",
      "Epoch 153/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0230 - accuracy: 0.9952 - val_loss: 0.0224 - val_accuracy: 0.9938\n",
      "Epoch 154/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0227 - accuracy: 0.9946 - val_loss: 0.0237 - val_accuracy: 0.9938\n",
      "Epoch 155/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0232 - accuracy: 0.9948 - val_loss: 0.0217 - val_accuracy: 0.9946\n",
      "Epoch 156/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0229 - accuracy: 0.9958 - val_loss: 0.0218 - val_accuracy: 0.9946\n",
      "Epoch 157/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0228 - accuracy: 0.9954 - val_loss: 0.0218 - val_accuracy: 0.9938\n",
      "Epoch 158/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0231 - accuracy: 0.9956 - val_loss: 0.0214 - val_accuracy: 0.9946\n",
      "Epoch 159/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0230 - accuracy: 0.9958 - val_loss: 0.0214 - val_accuracy: 0.9946\n",
      "Epoch 160/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0228 - accuracy: 0.9956 - val_loss: 0.0218 - val_accuracy: 0.9946\n",
      "Epoch 161/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0227 - accuracy: 0.9956 - val_loss: 0.0217 - val_accuracy: 0.9938\n",
      "Epoch 162/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0226 - accuracy: 0.9960 - val_loss: 0.0217 - val_accuracy: 0.9946\n",
      "Epoch 163/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0226 - accuracy: 0.9952 - val_loss: 0.0215 - val_accuracy: 0.9946\n",
      "Epoch 164/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0223 - accuracy: 0.9956 - val_loss: 0.0230 - val_accuracy: 0.9915\n",
      "Epoch 165/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0224 - accuracy: 0.9960 - val_loss: 0.0224 - val_accuracy: 0.9946\n",
      "Epoch 166/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0223 - accuracy: 0.9954 - val_loss: 0.0214 - val_accuracy: 0.9946\n",
      "Epoch 167/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0225 - accuracy: 0.9954 - val_loss: 0.0214 - val_accuracy: 0.9946\n",
      "Epoch 168/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0224 - accuracy: 0.9958 - val_loss: 0.0214 - val_accuracy: 0.9946\n",
      "Epoch 169/300\n",
      "5197/5197 [==============================] - 0s 38us/sample - loss: 0.0222 - accuracy: 0.9960 - val_loss: 0.0210 - val_accuracy: 0.9946\n",
      "Epoch 170/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0223 - accuracy: 0.9962 - val_loss: 0.0215 - val_accuracy: 0.9938\n",
      "Epoch 171/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0221 - accuracy: 0.9956 - val_loss: 0.0211 - val_accuracy: 0.9946\n",
      "Epoch 172/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0220 - accuracy: 0.9960 - val_loss: 0.0248 - val_accuracy: 0.9915\n",
      "Epoch 173/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0216 - accuracy: 0.9956 - val_loss: 0.0214 - val_accuracy: 0.9946\n",
      "Epoch 174/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0218 - accuracy: 0.9960 - val_loss: 0.0227 - val_accuracy: 0.9931\n",
      "Epoch 175/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0220 - accuracy: 0.9956 - val_loss: 0.0208 - val_accuracy: 0.9946\n",
      "Epoch 176/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0219 - accuracy: 0.9960 - val_loss: 0.0206 - val_accuracy: 0.9946\n",
      "Epoch 177/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0216 - accuracy: 0.9960 - val_loss: 0.0209 - val_accuracy: 0.9946\n",
      "Epoch 178/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0215 - accuracy: 0.9960 - val_loss: 0.0220 - val_accuracy: 0.9946\n",
      "Epoch 179/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0219 - accuracy: 0.9958 - val_loss: 0.0209 - val_accuracy: 0.9946\n",
      "Epoch 180/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0217 - accuracy: 0.9962 - val_loss: 0.0209 - val_accuracy: 0.9946\n",
      "Epoch 181/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0216 - accuracy: 0.9960 - val_loss: 0.0208 - val_accuracy: 0.9946\n",
      "Epoch 182/300\n",
      "5197/5197 [==============================] - 0s 38us/sample - loss: 0.0216 - accuracy: 0.9956 - val_loss: 0.0210 - val_accuracy: 0.9946\n",
      "Epoch 183/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0219 - accuracy: 0.9960 - val_loss: 0.0206 - val_accuracy: 0.9946\n",
      "Epoch 184/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0211 - accuracy: 0.9958 - val_loss: 0.0228 - val_accuracy: 0.9923\n",
      "Epoch 185/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0214 - accuracy: 0.9956 - val_loss: 0.0204 - val_accuracy: 0.9946\n",
      "Epoch 186/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0210 - accuracy: 0.9958 - val_loss: 0.0204 - val_accuracy: 0.9946\n",
      "Epoch 187/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0213 - accuracy: 0.9962 - val_loss: 0.0207 - val_accuracy: 0.9946\n",
      "Epoch 188/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0211 - accuracy: 0.9960 - val_loss: 0.0218 - val_accuracy: 0.9954\n",
      "Epoch 189/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0213 - accuracy: 0.9960 - val_loss: 0.0208 - val_accuracy: 0.9938\n",
      "Epoch 190/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0212 - accuracy: 0.9958 - val_loss: 0.0205 - val_accuracy: 0.9946\n",
      "Epoch 191/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0211 - accuracy: 0.9960 - val_loss: 0.0203 - val_accuracy: 0.9946\n",
      "Epoch 192/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0212 - accuracy: 0.9956 - val_loss: 0.0203 - val_accuracy: 0.9946\n",
      "Epoch 193/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0211 - accuracy: 0.9960 - val_loss: 0.0205 - val_accuracy: 0.9946\n",
      "Epoch 194/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0209 - accuracy: 0.9960 - val_loss: 0.0205 - val_accuracy: 0.9946\n",
      "Epoch 195/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0211 - accuracy: 0.9954 - val_loss: 0.0204 - val_accuracy: 0.9946\n",
      "Epoch 196/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0211 - accuracy: 0.9960 - val_loss: 0.0204 - val_accuracy: 0.9946\n",
      "Epoch 197/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0207 - accuracy: 0.9960 - val_loss: 0.0206 - val_accuracy: 0.9946\n",
      "Epoch 198/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0208 - accuracy: 0.9962 - val_loss: 0.0202 - val_accuracy: 0.9946\n",
      "Epoch 199/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0208 - accuracy: 0.9960 - val_loss: 0.0204 - val_accuracy: 0.9946\n",
      "Epoch 200/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0209 - accuracy: 0.9960 - val_loss: 0.0204 - val_accuracy: 0.9946\n",
      "Epoch 201/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0206 - accuracy: 0.9962 - val_loss: 0.0201 - val_accuracy: 0.9946\n",
      "Epoch 202/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0206 - accuracy: 0.9960 - val_loss: 0.0200 - val_accuracy: 0.9946\n",
      "Epoch 203/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0206 - accuracy: 0.9960 - val_loss: 0.0202 - val_accuracy: 0.9946\n",
      "Epoch 204/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0208 - accuracy: 0.9954 - val_loss: 0.0201 - val_accuracy: 0.9946\n",
      "Epoch 205/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0205 - accuracy: 0.9960 - val_loss: 0.0223 - val_accuracy: 0.9923\n",
      "Epoch 206/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0209 - accuracy: 0.9958 - val_loss: 0.0201 - val_accuracy: 0.9954\n",
      "Epoch 207/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0202 - accuracy: 0.9965 - val_loss: 0.0211 - val_accuracy: 0.9946\n",
      "Epoch 208/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0206 - accuracy: 0.9962 - val_loss: 0.0205 - val_accuracy: 0.9946\n",
      "Epoch 209/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0204 - accuracy: 0.9960 - val_loss: 0.0198 - val_accuracy: 0.9946\n",
      "Epoch 210/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0206 - accuracy: 0.9962 - val_loss: 0.0200 - val_accuracy: 0.9946\n",
      "Epoch 211/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0205 - accuracy: 0.9960 - val_loss: 0.0205 - val_accuracy: 0.9946\n",
      "Epoch 212/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0205 - accuracy: 0.9965 - val_loss: 0.0221 - val_accuracy: 0.9923\n",
      "Epoch 213/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0204 - accuracy: 0.9958 - val_loss: 0.0197 - val_accuracy: 0.9946\n",
      "Epoch 214/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0203 - accuracy: 0.9962 - val_loss: 0.0197 - val_accuracy: 0.9946\n",
      "Epoch 215/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0203 - accuracy: 0.9960 - val_loss: 0.0198 - val_accuracy: 0.9946\n",
      "Epoch 216/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0203 - accuracy: 0.9960 - val_loss: 0.0197 - val_accuracy: 0.9946\n",
      "Epoch 217/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0203 - accuracy: 0.9962 - val_loss: 0.0199 - val_accuracy: 0.9946\n",
      "Epoch 218/300\n",
      "5197/5197 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.99 - 0s 35us/sample - loss: 0.0203 - accuracy: 0.9960 - val_loss: 0.0198 - val_accuracy: 0.9946\n",
      "Epoch 219/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0201 - accuracy: 0.9962 - val_loss: 0.0197 - val_accuracy: 0.9946\n",
      "Epoch 220/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0203 - accuracy: 0.9962 - val_loss: 0.0197 - val_accuracy: 0.9946\n",
      "Epoch 221/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0198 - accuracy: 0.9965 - val_loss: 0.0198 - val_accuracy: 0.9954\n",
      "Epoch 222/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0200 - accuracy: 0.9960 - val_loss: 0.0196 - val_accuracy: 0.9946\n",
      "Epoch 223/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0199 - accuracy: 0.9960 - val_loss: 0.0196 - val_accuracy: 0.9954\n",
      "Epoch 224/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0200 - accuracy: 0.9960 - val_loss: 0.0195 - val_accuracy: 0.9946\n",
      "Epoch 225/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0200 - accuracy: 0.9960 - val_loss: 0.0197 - val_accuracy: 0.9946\n",
      "Epoch 226/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0198 - accuracy: 0.9960 - val_loss: 0.0199 - val_accuracy: 0.9954\n",
      "Epoch 227/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0203 - accuracy: 0.9962 - val_loss: 0.0196 - val_accuracy: 0.9946\n",
      "Epoch 228/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0199 - accuracy: 0.9960 - val_loss: 0.0195 - val_accuracy: 0.9946\n",
      "Epoch 229/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0198 - accuracy: 0.9958 - val_loss: 0.0194 - val_accuracy: 0.9946\n",
      "Epoch 230/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0197 - accuracy: 0.9960 - val_loss: 0.0195 - val_accuracy: 0.9954\n",
      "Epoch 231/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0196 - accuracy: 0.9962 - val_loss: 0.0196 - val_accuracy: 0.9954\n",
      "Epoch 232/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0198 - accuracy: 0.9956 - val_loss: 0.0195 - val_accuracy: 0.9954\n",
      "Epoch 233/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0198 - accuracy: 0.9958 - val_loss: 0.0195 - val_accuracy: 0.9954\n",
      "Epoch 234/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0195 - accuracy: 0.9963 - val_loss: 0.0193 - val_accuracy: 0.9954\n",
      "Epoch 235/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0198 - accuracy: 0.9960 - val_loss: 0.0200 - val_accuracy: 0.9954\n",
      "Epoch 236/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0197 - accuracy: 0.9962 - val_loss: 0.0199 - val_accuracy: 0.9954\n",
      "Epoch 237/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0195 - accuracy: 0.9962 - val_loss: 0.0198 - val_accuracy: 0.9954\n",
      "Epoch 238/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0196 - accuracy: 0.9962 - val_loss: 0.0192 - val_accuracy: 0.9954\n",
      "Epoch 239/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0195 - accuracy: 0.9960 - val_loss: 0.0194 - val_accuracy: 0.9954\n",
      "Epoch 240/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0194 - accuracy: 0.9963 - val_loss: 0.0196 - val_accuracy: 0.9954\n",
      "Epoch 241/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0196 - accuracy: 0.9962 - val_loss: 0.0193 - val_accuracy: 0.9946\n",
      "Epoch 242/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0194 - accuracy: 0.9962 - val_loss: 0.0191 - val_accuracy: 0.9954\n",
      "Epoch 243/300\n",
      "5197/5197 [==============================] - 0s 38us/sample - loss: 0.0196 - accuracy: 0.9962 - val_loss: 0.0198 - val_accuracy: 0.9946\n",
      "Epoch 244/300\n",
      "5197/5197 [==============================] - 0s 38us/sample - loss: 0.0193 - accuracy: 0.9962 - val_loss: 0.0193 - val_accuracy: 0.9954\n",
      "Epoch 245/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0193 - accuracy: 0.9962 - val_loss: 0.0194 - val_accuracy: 0.9954\n",
      "Epoch 246/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0194 - accuracy: 0.9962 - val_loss: 0.0193 - val_accuracy: 0.9954\n",
      "Epoch 247/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0195 - accuracy: 0.9960 - val_loss: 0.0190 - val_accuracy: 0.9954\n",
      "Epoch 248/300\n",
      "5197/5197 [==============================] - 0s 38us/sample - loss: 0.0191 - accuracy: 0.9963 - val_loss: 0.0202 - val_accuracy: 0.9946\n",
      "Epoch 249/300\n",
      "5197/5197 [==============================] - 0s 42us/sample - loss: 0.0191 - accuracy: 0.9962 - val_loss: 0.0189 - val_accuracy: 0.9954\n",
      "Epoch 250/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0193 - accuracy: 0.9960 - val_loss: 0.0193 - val_accuracy: 0.9946\n",
      "Epoch 251/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0194 - accuracy: 0.9960 - val_loss: 0.0194 - val_accuracy: 0.9954\n",
      "Epoch 252/300\n",
      "5197/5197 [==============================] - 0s 41us/sample - loss: 0.0191 - accuracy: 0.9963 - val_loss: 0.0193 - val_accuracy: 0.9954\n",
      "Epoch 253/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0191 - accuracy: 0.9960 - val_loss: 0.0190 - val_accuracy: 0.9954\n",
      "Epoch 254/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0191 - accuracy: 0.9962 - val_loss: 0.0192 - val_accuracy: 0.9954\n",
      "Epoch 255/300\n",
      "5197/5197 [==============================] - 0s 38us/sample - loss: 0.0190 - accuracy: 0.9963 - val_loss: 0.0197 - val_accuracy: 0.9946\n",
      "Epoch 256/300\n",
      "5197/5197 [==============================] - 0s 38us/sample - loss: 0.0190 - accuracy: 0.9962 - val_loss: 0.0190 - val_accuracy: 0.9954\n",
      "Epoch 257/300\n",
      "5197/5197 [==============================] - 0s 39us/sample - loss: 0.0194 - accuracy: 0.9960 - val_loss: 0.0191 - val_accuracy: 0.9946\n",
      "Epoch 258/300\n",
      "5197/5197 [==============================] - 0s 42us/sample - loss: 0.0192 - accuracy: 0.9963 - val_loss: 0.0194 - val_accuracy: 0.9954\n",
      "Epoch 259/300\n",
      "5197/5197 [==============================] - 0s 38us/sample - loss: 0.0190 - accuracy: 0.9965 - val_loss: 0.0189 - val_accuracy: 0.9954\n",
      "Epoch 260/300\n",
      "5197/5197 [==============================] - 0s 42us/sample - loss: 0.0193 - accuracy: 0.9958 - val_loss: 0.0191 - val_accuracy: 0.9954\n",
      "Epoch 261/300\n",
      "5197/5197 [==============================] - 0s 39us/sample - loss: 0.0188 - accuracy: 0.9960 - val_loss: 0.0188 - val_accuracy: 0.9954\n",
      "Epoch 262/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0193 - accuracy: 0.9960 - val_loss: 0.0188 - val_accuracy: 0.9954\n",
      "Epoch 263/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0191 - accuracy: 0.9962 - val_loss: 0.0192 - val_accuracy: 0.9954\n",
      "Epoch 264/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0189 - accuracy: 0.9963 - val_loss: 0.0188 - val_accuracy: 0.9962\n",
      "Epoch 265/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0190 - accuracy: 0.9962 - val_loss: 0.0202 - val_accuracy: 0.9954\n",
      "Epoch 266/300\n",
      "5197/5197 [==============================] - 0s 38us/sample - loss: 0.0186 - accuracy: 0.9963 - val_loss: 0.0195 - val_accuracy: 0.9946\n",
      "Epoch 267/300\n",
      "5197/5197 [==============================] - 0s 38us/sample - loss: 0.0187 - accuracy: 0.9962 - val_loss: 0.0187 - val_accuracy: 0.9962\n",
      "Epoch 268/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0188 - accuracy: 0.9963 - val_loss: 0.0188 - val_accuracy: 0.9954\n",
      "Epoch 269/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0186 - accuracy: 0.9962 - val_loss: 0.0194 - val_accuracy: 0.9946\n",
      "Epoch 270/300\n",
      "5197/5197 [==============================] - 0s 39us/sample - loss: 0.0189 - accuracy: 0.9958 - val_loss: 0.0192 - val_accuracy: 0.9954\n",
      "Epoch 271/300\n",
      "5197/5197 [==============================] - 0s 39us/sample - loss: 0.0186 - accuracy: 0.9965 - val_loss: 0.0190 - val_accuracy: 0.9962\n",
      "Epoch 272/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0185 - accuracy: 0.9963 - val_loss: 0.0202 - val_accuracy: 0.9946\n",
      "Epoch 273/300\n",
      "5197/5197 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.99 - 0s 35us/sample - loss: 0.0188 - accuracy: 0.9960 - val_loss: 0.0189 - val_accuracy: 0.9954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 274/300\n",
      "5197/5197 [==============================] - 0s 39us/sample - loss: 0.0186 - accuracy: 0.9962 - val_loss: 0.0190 - val_accuracy: 0.9954\n",
      "Epoch 275/300\n",
      "5197/5197 [==============================] - 0s 38us/sample - loss: 0.0185 - accuracy: 0.9962 - val_loss: 0.0191 - val_accuracy: 0.9954\n",
      "Epoch 276/300\n",
      "5197/5197 [==============================] - 0s 38us/sample - loss: 0.0189 - accuracy: 0.9960 - val_loss: 0.0190 - val_accuracy: 0.9954\n",
      "Epoch 277/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0185 - accuracy: 0.9962 - val_loss: 0.0187 - val_accuracy: 0.9954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fe65b2a240>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_X_train, \n",
    "          y=y_train, \n",
    "          epochs=300,\n",
    "          validation_data=(scaled_X_test, y_test), verbose=1 ,callbacks=[early_stop]         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.554537</td>\n",
       "      <td>0.737733</td>\n",
       "      <td>0.449349</td>\n",
       "      <td>0.765385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.374026</td>\n",
       "      <td>0.829709</td>\n",
       "      <td>0.292592</td>\n",
       "      <td>0.892308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.232251</td>\n",
       "      <td>0.948624</td>\n",
       "      <td>0.180227</td>\n",
       "      <td>0.962308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.148462</td>\n",
       "      <td>0.975370</td>\n",
       "      <td>0.125253</td>\n",
       "      <td>0.974615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.110546</td>\n",
       "      <td>0.979219</td>\n",
       "      <td>0.097304</td>\n",
       "      <td>0.979231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>0.018833</td>\n",
       "      <td>0.995959</td>\n",
       "      <td>0.018851</td>\n",
       "      <td>0.995385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>0.018616</td>\n",
       "      <td>0.996152</td>\n",
       "      <td>0.018960</td>\n",
       "      <td>0.995385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>0.018459</td>\n",
       "      <td>0.996152</td>\n",
       "      <td>0.019090</td>\n",
       "      <td>0.995385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>0.018864</td>\n",
       "      <td>0.995959</td>\n",
       "      <td>0.018976</td>\n",
       "      <td>0.995385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0.018452</td>\n",
       "      <td>0.996152</td>\n",
       "      <td>0.018716</td>\n",
       "      <td>0.995385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>277 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy  val_loss  val_accuracy\n",
       "0    0.554537  0.737733  0.449349      0.765385\n",
       "1    0.374026  0.829709  0.292592      0.892308\n",
       "2    0.232251  0.948624  0.180227      0.962308\n",
       "3    0.148462  0.975370  0.125253      0.974615\n",
       "4    0.110546  0.979219  0.097304      0.979231\n",
       "..        ...       ...       ...           ...\n",
       "272  0.018833  0.995959  0.018851      0.995385\n",
       "273  0.018616  0.996152  0.018960      0.995385\n",
       "274  0.018459  0.996152  0.019090      0.995385\n",
       "275  0.018864  0.995959  0.018976      0.995385\n",
       "276  0.018452  0.996152  0.018716      0.995385\n",
       "\n",
       "[277 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAjHklEQVR4nO3deZRcd3nm8e97l6rqVWtLrcWLbARCqI1NZAMJiGFywEvAxuADAgOGkPgYYrY59tgcThhPCCcDnkAmiQfHmTFL4sTyYUk8scBZYEY4GKOWkSzLxrIQttRarO6W1FIv1bW988etbrVaLakkt1R9W8/nnDpddet29ftT2c/91XuXMndHRETSL6h3ASIiMjkU6CIi04QCXURkmlCgi4hMEwp0EZFpIqrXH547d65feOGF9frzIiKptGHDhh53b5vouboF+oUXXkhnZ2e9/ryISCqZ2YvHe04tFxGRaUKBLiIyTSjQRUSmibr10EXk3FQsFunq6iKfz9e7lCktl8uxePFi4jiu+XcU6CJyVnV1ddHS0sKFF16ImdW7nCnJ3ent7aWrq4slS5bU/HtquYjIWZXP55kzZ47C/ATMjDlz5pzypxgFuoicdQrzkzudf6PUBfpzew/zp//8HD39w/UuRURkSkldoP+qu5+/+NE2evsL9S5FRFKqubm53iWcEakL9DBIPoaUKpU6VyIiMrWkLtCjaqCXK/qmJRF5edyd22+/nRUrVtDR0cGaNWsA2LNnD6tWreLSSy9lxYoV/OQnP6FcLvORj3xkdN2vfe1rda7+WKk7bHFkhl4sK9BF0u6//p8tPLP70KS+5vKFrfyXd76mpnW/973vsXHjRjZt2kRPTw+XX345q1at4u/+7u+48sor+fznP0+5XGZwcJCNGzeya9cunn76aQAOHjw4qXVPhtTN0OMwKVkzdBF5uR577DHe//73E4Yh8+fP5y1veQvr16/n8ssv5xvf+AZ33XUXmzdvpqWlhYsuuojt27fzyU9+kh/+8Ie0trbWu/xjpHaGrh66SPrVOpM+U9wnnhiuWrWKdevW8cgjj/ChD32I22+/nQ9/+MNs2rSJRx99lHvuuYeHHnqI+++//yxXfGKpm6Grhy4ik2XVqlWsWbOGcrlMd3c369at44orruDFF19k3rx5/P7v/z4f+9jHePLJJ+np6aFSqfCe97yHL37xizz55JP1Lv8Y6Z2hq4cuIi/T9ddfz+OPP85rX/tazIyvfOUrtLe3861vfYu7776bOI5pbm7m29/+Nrt27eKjH/0olWp34E/+5E/qXP2xUhfoUZB8qChphi4ip6m/vx9Izsa8++67ufvuu496/qabbuKmm2465vem4qx8rPS1XMKRlot66CIiY6Uv0Ed3imqGLiIyVuoCXT10EZGJpS7Q1UMXEZlY+gJdPXQRkQmlL9DVQxcRmVDqAj3UiUUiIhNKXaCP9NB1cS4RORtOdO30F154gRUrVpzFak6spkA3s6vM7Dkz22Zmd07w/H8wsz4z21i9fWHyS02ohy4iMrGTnilqZiFwD/A2oAtYb2YPu/sz41b9ibu/4wzUeJRQPXSR6eMHd8LezZP7mu0dcPV/O+7Td9xxBxdccAGf+MQnALjrrrswM9atW8eBAwcoFov88R//Mdddd90p/dl8Ps/HP/5xOjs7iaKIr371q7z1rW9ly5YtfPSjH6VQKFCpVPjud7/LwoULee9730tXVxflcpk//MM/5H3ve9/LGjbUdur/FcA2d98OYGYPAtcB4wP9rBi9OJdaLiJyGlavXs1nPvOZ0UB/6KGH+OEPf8hnP/tZWltb6enp4Q1veAPXXnvtKX1R8z333APA5s2b+eUvf8nb3/52tm7dyr333sunP/1pbrzxRgqFAuVymbVr17Jw4UIeeeQRAPr6+iZlbLUE+iJg55jHXcDrJ1jvjWa2CdgN3ObuW8avYGY3AzcDnH/++adeLWO+4EIzdJH0O8FM+ky57LLL2LdvH7t376a7u5tZs2axYMECPvvZz7Ju3TqCIGDXrl289NJLtLe31/y6jz32GJ/85CcBWLZsGRdccAFbt27ljW98I1/60pfo6uri3e9+N0uXLqWjo4PbbruNO+64g3e84x28+c1vnpSx1dJDn2gTNT5NnwQucPfXAn8B/MNEL+Tu97n7Sndf2dbWdkqFjhZjRhiYeugictpuuOEGvvOd77BmzRpWr17NAw88QHd3Nxs2bGDjxo3Mnz+ffD5/Sq95vGurf+ADH+Dhhx+moaGBK6+8kh/96Ee88pWvZMOGDXR0dPC5z32OP/qjP5qMYdUU6F3AeWMeLyaZhY9y90Pu3l+9vxaIzWzupFQ4gSgw9dBF5LStXr2aBx98kO985zvccMMN9PX1MW/ePOI45sc//jEvvvjiKb/mqlWreOCBBwDYunUrO3bs4FWvehXbt2/noosu4lOf+hTXXnstTz31FLt376axsZEPfvCD3HbbbZN2FcdaWi7rgaVmtgTYBawGPjB2BTNrB15ydzezK0g2FL2TUuEEosDUQxeR0/aa17yGw4cPs2jRIhYsWMCNN97IO9/5TlauXMmll17KsmXLTvk1P/GJT3DLLbfQ0dFBFEV885vfJJvNsmbNGv72b/+WOI5pb2/nC1/4AuvXr+f2228nCALiOObrX//6pIzLjvcx4aiVzK4B/gwIgfvd/UtmdguAu99rZrcCHwdKwBDwn9z9pyd6zZUrV3pnZ+dpFX3JXY/y7tct5q5r6/v1VSJy6p599lle/epX17uMVJjo38rMNrj7yonWr+kLLqptlLXjlt075v5fAn95ytWepigM9J2iIiLjpO4bi6DaclEPXUTOks2bN/OhD33oqGXZbJYnnniiThVNLLWBruuhi6SXu5/SMd711tHRwcaNG8/q36ylHT5e6q7lAhCGmqGLpFUul6O3t/e0Autc4e709vaSy+VO6fdSOkMPdGKRSEotXryYrq4uuru7613KlJbL5Vi8ePEp/U5KA10nFomkVRzHLFmypN5lTEvpbLmohy4icoxUBnqkHrqIyDFSGeiheugiIsdIZaDH6qGLiBwjlYGuHrqIyLFSGejqoYuIHCuVga4euojIsdIX6C88xn/edyezi3vrXYmIyJSSvkAf6GFFfgPZ8kC9KxERmVLSF+hhDIBVSnUuRERkaklfoAcjgV6scyEiIlNL+gI9rF5+RoEuInKU9AV6kAR6oJaLiMhRUhjoScuFSrm+dYiITDHpC/TqTtHANUMXERkrfYEeqIcuIjKR9AV6dYYeqocuInKU9AX6yGGLarmIiBwlfYFePWxRPXQRkaOlL9CDIztF9a3hIiJHpC/Qqz30mLIuoSsiMkb6Ar16lEtImZICXURkVGoDXTN0EZGj1RToZnaVmT1nZtvM7M4TrHe5mZXN7IbJK3GcassloqyvoRMRGeOkgW5mIXAPcDWwHHi/mS0/znpfBh6d7CKPEowJdH1RtIjIqFpm6FcA29x9u7sXgAeB6yZY75PAd4F9k1jfsUZ2ilpJLRcRkTFqCfRFwM4xj7uqy0aZ2SLgeuDeE72Qmd1sZp1m1tnd3X2qtY68CBULqzN0BbqIyIhaAt0mWDY+Sf8MuMPdT3gJRHe/z91XuvvKtra2Gkuc4HUsUg9dRGScqIZ1uoDzxjxeDOwet85K4EEzA5gLXGNmJXf/h8kocrxKEBGrhy4icpRaAn09sNTMlgC7gNXAB8au4O5LRu6b2TeBfzpTYQ7gQUSEeugiImOdNNDdvWRmt5IcvRIC97v7FjO7pfr8CfvmZ0LScqmohy4iMkYtM3TcfS2wdtyyCYPc3T/y8ss6ST1B0kPXDF1E5Ij0nSkKeBATWYliWT10EZERKQ30SKf+i4iMk8pAJ4h1HLqIyDipDPSRGbqOQxcROSKVgU4YE1GiqOPQRURGpTPQR1oumqGLiIxKZaBbGBJbmZKOchERGZXKQCeICSlTUKCLiIxKZaBbGGunqIjIOKkN9IiyTiwSERkjlYHOSKDrOHQRkVGpDPQgjIkpUSxphi4iMiKVgW5RrO8UFREZJ5WBHoQxkZUpaqeoiMiodAZ6lCHWTlERkaOkMtAtiAh12KKIyFFSGehUj0PXDF1E5Ih0Bnr1G4vUQxcROSKdgR7GxFbSUS4iImOkM9CDasulVK53JSIiU0Y6Az2MASiXS3UuRERk6khnoAcRAJVSsc6FiIhMHekM9OoM3RXoIiKj0hnowUjLpVDnQkREpo6UBnoIgKuHLiIyKp2BPtJyKavlIiIyIp2BXm25aKeoiMgR6Qz06gydigJdRGRETYFuZleZ2XNmts3M7pzg+evM7Ckz22hmnWb2pskvdYzqYYtquYiIHBGdbAUzC4F7gLcBXcB6M3vY3Z8Zs9q/AQ+7u5vZJcBDwLIzUTBwZIaunaIiIqNqmaFfAWxz9+3uXgAeBK4bu4K797v7yJWymoAze9WsQC0XEZHxagn0RcDOMY+7qsuOYmbXm9kvgUeA353ohczs5mpLprO7u/t06k2E1Q8WarmIiIyqJdBtgmXHzMDd/fvuvgx4F/DFiV7I3e9z95XuvrKtre2UCj1KtYeuGbqIyBG1BHoXcN6Yx4uB3cdb2d3XAReb2dyXWdvxjbRcNEMXERlVS6CvB5aa2RIzywCrgYfHrmBmrzAzq95/HZABeie72FFRFoDAtVNURGTESY9ycfeSmd0KPAqEwP3uvsXMbqk+fy/wHuDDZlYEhoD3jdlJOvmqR7kEFV3LRURkxEkDHcDd1wJrxy27d8z9LwNfntzSTiCsztAV6CIio9J5pmiUASDUTlERkVHpDPTqDD3yImeysyMikibpDPTqTtEMRYplBbqICKQ10MOk5ZKhRLFcqXMxIiJTQ+oDvaQZuogIkPZAtyLFimboIiKQ1kAPAsoWqeUiIjJGOgMdqAQZMhTVchERqUpvoIcZMpQoaIYuIgKkONA9iDVDFxEZI8WBniE29dBFREakNtArYZasdoqKiIxKbaB7WN0pWlHLRUQEUhzoVHeKFkuaoYuIQIoD3aNkhl7UDF1EBEhxoBNmyJhm6CIiI1Ic6FliSpR06r+ICJDiQLeRlouOQxcRAVId6Fldy0VEZIxUB3rWihTUQxcRAVIc6EGcI0OJfLFc71JERKaE1AZ6GCc99Lxm6CIiQIoDPYpzxJqhi4iMSm2gj+wUzRc1QxcRgRQHOlGW2MoMF4r1rkREZEpIb6BXv1e0WMjXuRARkakhvYEeZQEoF4bqXIiIyNSQ3kCvztBLheE6FyIiMjXUFOhmdpWZPWdm28zszgmev9HMnqrefmpmr538UsepBnq5pEAXEYEaAt3MQuAe4GpgOfB+M1s+brVfA29x90uALwL3TXahxxhpuRQV6CIiUNsM/Qpgm7tvd/cC8CBw3dgV3P2n7n6g+vBnwOLJLXMC1Rl6RYEuIgLUFuiLgJ1jHndVlx3Px4AfTPSEmd1sZp1m1tnd3V17lROpztC9qKNcRESgtkC3CZZNeM1aM3srSaDfMdHz7n6fu69095VtbW21VzmRMAn0inroIiIARDWs0wWcN+bxYmD3+JXM7BLgfwFXu3vv5JR3AmGc/CwVzvifEhFJg1pm6OuBpWa2xMwywGrg4bErmNn5wPeAD7n71skvcwIjLZeyAl1EBGqYobt7ycxuBR4FQuB+d99iZrdUn78X+AIwB/ifZgZQcveVZ65sRneKopaLiAhQW8sFd18LrB237N4x938P+L3JLe0kqjN0ygXcneqGRETknJXiM0WTQM9QZFjXRBcRSXGgV2foOSvqmugiIqQ50LMtADQzpGuii4gwbQJdM3QRkfQGehBSChtptiHyJQW6iEh6Ax0ox81quYiIVKU70DPNtJhaLiIikPJA90yLeugiIlXpDvRsM02mlouICKQ80Mm2aoYuIlKV6kC3bIt66CIiVakO9CCnGbqIyIhUB3rYoEAXERlR09UWp6qoYQaBVRga7K93KSIidZfqGXqQS07/Hzx8sL6FiIhMAakOdLKtAAz3H6xvHSIiU0DKA70ZgOGhQ3UuRESk/lIe6EnLpTTYV+dCRETqb1oEuuc1QxcRmRaBzvBhKhWvby0iInWW8kBPdoo2McShfLHOxYiI1FfKAz2ZobcyyP6BQp2LERGpr3QHepSlmJnJfDvAgUEFuoic29Id6ECpqZ12209vvwJdRM5tqQ90WhfSbvs1QxeRc17qAz2etYh2O8D+Ae0UFZFzW+oDPZyxkLn0cfDwQL1LERGpq9QHurUuIjCnv7er3qWIiNRVTYFuZleZ2XNmts3M7pzg+WVm9riZDZvZbZNf5gm0LgRgsEeBLiLntpNeD93MQuAe4G1AF7DezB5292fGrLYf+BTwrjNR5Am1LACg0reLSsUJAjvrJYiITAW1zNCvALa5+3Z3LwAPAteNXcHd97n7euDs75msztDnVHrZcyh/1v+8iMhUUUugLwJ2jnncVV12yszsZjPrNLPO7u7u03mJYzXMohzmWGC9/LpbO0ZF5NxVS6BP1MM4rSthuft97r7S3Ve2tbWdzkscy4zK7ItZarvY3qOvohORc1ctgd4FnDfm8WJg95kp5/RECy/hNcGLbNcMXUTOYbUE+npgqZktMbMMsBp4+MyWdWpswWtps4Ps2vlCvUsREambkx7l4u4lM7sVeBQIgfvdfYuZ3VJ9/l4zawc6gVagYmafAZa7+9n55on2DgDKezYxVLiKhkx4Vv6siMhUctJAB3D3tcDaccvuHXN/L0krpj7mrwBgmb9A54v7efPSSerPi4ikSOrPFAWgYSaVGedzSfhr/n1bb72rERGpi+kR6ECwZBVvCp/h/z27B3d9HZ2InHumTaCz9G00ez9N3U+yqauv3tWIiJx10yfQL34rHkS8LX6Kv39iR72rERE566ZPoOdmYOe/kXfnNvD9jV3s6Ruqd0UiImfV9Al0gMs+SFthJ29gC//jX5+vdzUiImfV9Ar05e+Chtl8bu5jrOncyRPbdcSLiJw7plegxzlY+bu8+uD/5aoZXXx2zUb29ukKjCJybphegQ7wps9Acztfbfo2xXw/7//rn7G9WxftEpHpb/oFerYF3vFVGvY/w4/a/5LDAwO88y8e4x837qp3ZSIiZ9T0C3SAZb8D1/8VLS/9nB9f/nOWLWjl0w9u5CPf+Dkbdx6sd3UiImfE9Ax0gEveC5feSMv6P2fN5c9zx5WvYtPOg7zrnn/nfX/1OP/wi13ki+V6VykiMmmsXqfJr1y50js7O8/sH8kfgoc+DNt/DPM7GLzybv5m5zweeGIHO/YP0pKNeMur2lh5wSyuv2wxMxrjM1uPiMjLZGYb3H3lhM9N60AHKJfgF38Dj30NBrrhmv9OpeN9PP7CQb7/i138dFsPu/vyxKHxyvktdCyawYpFM+hYNINlC1rIRroUr4hMHed2oI/o3wcPfgC61kNzOyy/Dl5zPZz3ep7Z28/Dm3bz9K4+Nu/qo28o+a7rKDgS8vNbs2TjkMsvnM2Fcxtpa85iNtG384mInDkK9BHu8MtHYNPfw/P/AuVhaFkIS98Gsy6A+R14pomu5g427xlg866+0ZA/OFg86qVyccB5sxpZNKuBhTMbWNbewvzWHLk4pL01x/zWLDMaYoW+iEwqBfpEhg/Dcz+ALd+HF38K+YNHnmvvgMs+DIM90DALf8XbqMy+mL6hIht3HmDn/iF27B9k5/5BdvcNsevAEAfGBT5ANgqYXw33+a055rXkiENjZmOG5lzEnKYMr5zfTBgERIExozGmJRtpIyAix6VAr8XQQdj3LBx4AX78JejbCRhQ/ffJzYSWdpi3HHIzYO9TsOI9cMFv4Xs3cyBfoXv2b3Aot5C9fXleOpRn3+Hho+6/dChPqeIUSpXjlhEGxoyGePQ2szFmZvV+Ng4pliu05OKj1pnRENOSi2jKRDRmQ5oyEbk40IZBZBpSoJ8qdzi0KwnxwZ6kPbPvWTi0G/ZtSfrxsy9O7h/FYO4roXF28rthDPk+mLsUGuckJz1lW8gHjeSDRroLWXbmc1ApkTm0g+2NHfQUMuwfdg4N5JnZ9yw7iq1sH57BwcECYXmQOcEg24ZnnnQIZiQBnwlpylZ/jgn8o5af4PmmbERTJqQxG9EYhwSBNhIi9aRAn2zuSWLufRp6n4e5rwIL4NmHk5n70MHkVh5OQrxnGwyfwpduZFuhOASVIlgICy+DuAH2PAXDfVRW3EChdQml/S/CwRc5OKuD3pZlDHiWwUrEYDlgsGQMlozhYgkf7ucFFlIZHmCgBL3FDD2FDL2FiIFCmVKl9v8GGuKQpmw17DMRzbmI5mrwtzVnCQziKNm/4DiNmZDGTEQuDhkcLpGJAlpyySeK1oaYODAqDs25ZMOhTxUiJ3aiQK/pS6JlnJHQaV+R3EbMW3b836lUoNCf9O5Hfg4fgoHeJLhnng9dnVAuJodXxg1JL3/vZtj9CygNw7JroGEWwYZvkSsOQMsCaF1I83PfZHGldBrjCKC5EQ9jPIipBDGVIEOQP0AxM5PBxkUULIOXCgxblv5wBvHwQZrye9kRv4Jen8mhgSz9fRGHSwH78zBMRKsf5qD3ctgb2VBZyjw7yELr4UWfzzAx+72Vl3wWWSvSzn4cY5NfjJkxM+u0xkZvKcOKcCelhjkM5trJRgG5ODzmZ2M2pDkTkYkCwsAIAyMKjKD6MxeHLJjRQKFUIQhgqFDGDHJxSEMc0pAJyUXVn9VlcWhTa8NSGEzeqzhX70pkitMMPY3coVJKWjqQfBoY6E42EuVCslGolJIbQJSDnq3JzB+vbkyqG5bCYLJBKReSjUYpDw2zYWg/HNwBpQJEGRjuT5ZlmqF1Ibz0dHLiFhP/9+NBhJ3ORqaqTEhIciZvXzCTIhFFIgrE9NPIYW9gwDM0VfrJe0yj5Rn0HP00cKHtpYkhHq8sJ8Bpsz52ehuD5CgR0OfNzLZDNFCgx2fQzQwiylxi22myPD+rLKcUNjActTA7HKRULHDQW5jXCLPjEl3xBbRW+tgXtpMPcsxtCOgYfILZ3kepaR7t5b0E5Tz/OudGZsyYSRQEHKaR4bLTEJRoigMaGnIEQcTi/Y/TNrSdvvmv5/Cs5TjJxmTkk1ALAyz8zjsJcIrX/BmD+TyH2n+TpuqnnMzwQQ7RgoVGYxziwGChTK6/i+yBrbD07UcmIJUyBJNwXkW5lOxrmvuKiZ8vDiX/LTXMfPl/S46hloucGZUKFAeqG4Lh6sakcCT0+/clny5mLE4e7/81eBn6X4KBHggz0LogCYC9T0MYJcssSNZpWwaH90Bf15ENVXHoyKebwiA0zKRSzONxY7K8OEi5qR0PM0R7N+JBRD4zm4aBLqw8jFVKGE7FIiphlqg0MDqcfDyTkmVoLux7Wf8sBQ9xjKwd2aANepYSIa02eOSfz43Ajvz/1+85DtHIkGcZJsN8209EmUaGqRCQteRIql9UXsEun8sFtpeO4AV2VNrY5W0EViGgwqDn+I3geZptiMeClfTEi5hf7OLyyka223n8yi5kMGzBg4iYEpmgQhxApVIBr5CLAg7Hc8GMjA9TsgwD0QwCCwjLeZYf/ilLh5+ms+G3aIuG6I3b2d24HDNnZr6L1x74Z0Iv8aPFf8BQZjZhAIEFRFYmooIFARZEEMZYGGNBRGROaE5Eiah4iH3DEZmmOWSy2eQfxwww3Iw408CMqEjppeewMMQyjZRmXEQYxWRKhwnCiErjXKwwQHhoBw3zLiaIs7iFEMTkdq6j1Ho+hbYVBEP7Ccp5PIjxMAOVMtHhnZRmvYJK3AxexrwM7jQ1t5BtbOXAocM0+wCNmYDo+R8k+9MWX558qj68F4qD0DArmUT1PA/Lr00mU5UyeCWZiL2MT4AKdJER7jB0ADJNEGWTjcLAvuR/ttkXJev0bE02KkMHkp3bUTa5H4TJPo3ebdDUlnyCKQ8nv3v+G6HtVXhfF0NksaFectv/haIHVCpl4oG9BF6i3DA3+bRRyOOlAoNN57Ov7fW07H2C5p5NBMUBgtIQXswzmJmDFwb51dz/SJ83MGdgG7k44uI9/0RY7Kc/nsMLzZdx3vDzxKV+Sh6ABTSUD3MwmMXztoQ3H/4nwkqBw/FcnsldxuLSDmYVX6KxfIjAy5QsokJAmQAnwM2gUmam9xHgFIiJKBGM+STWTxM/CS7ntyuP8XxlEQuCA8zmEADDxDzJq5lFH8t4sQ5v8Jk17BEx5aM2xABFQopENDJ80tfIk2HLkt/lN2768mnVoEAXkVNTLiUbtSBINlj5vmR2GTcmM8wwBncqDoGRHOYbZpMNXRAkrbruXzLSknOvULGYMka54pRLBSrFYvKzXEqWu1EhpJxtpS1XZuBgD8VCAXBGcsq8RGG4QH/RyS18NRU3yvl+ov3bKJXLDMetUCkRDfWCBeRbl1DavwO8TOBFotIg+2d20NL/AtnCfoYzsyiHOYJKkbBSwDGGGubT0v9rgkoRtwC3ELeA0mAf4fAh4oYmBqwZy/fxdOubiAf2csHgU2S8yOHcQopxC3HxEH3lHHvixVw2/CTFcoV82WjIRli+j4alq3jD1R88rbdGO0VF5NSEY6IhCJNDccczY/Qo1pnnH/1clIEFlxxZFQirt1o1nHcKK/Obp7LypHlDTWudXnCfjul7+VwRkXOMAl1EZJqoKdDN7Coze87MtpnZnRM8b2b259XnnzKz101+qSIiciInDXQzC4F7gKuB5cD7zWz5uNWuBpZWbzcDX5/kOkVE5CRqmaFfAWxz9+3uXgAeBK4bt851wLc98TNgppktmORaRUTkBGoJ9EXAzjGPu6rLTnUdzOxmM+s0s87u7u5TrVVERE6glkCf6JSm8Qev17IO7n6fu69095VtbW211CciIjWqJdC7gLFHhC4Gdp/GOiIicgad9ExRM4uArcBvA7uA9cAH3H3LmHV+B7gVuAZ4PfDn7n7FSV63G0773OC5QM9p/m4aTOfxaWzppLFNHRe4+4QtjpOeKeruJTO7FXiU5ESv+919i5ndUn3+XmAtSZhvAwaBj9bwuqfdczGzzuOd+jodTOfxaWzppLGlQ02n/rv7WpLQHrvs3jH3HfiDyS1NREROhc4UFRGZJtIa6PfVu4AzbDqPT2NLJ40tBep2+VwREZlcaZ2hi4jIOAp0EZFpInWBfrIrP6aNmb1gZpvNbKOZdVaXzTazfzGz56s/Z9W7zlqY2f1mts/Mnh6z7LhjMbPPVd/H58zsyvpUXZvjjO0uM9tVfe82mtk1Y55L09jOM7Mfm9mzZrbFzD5dXZ769+4EY5sW790x3D01N5Lj4H8FXARkgE3A8nrX9TLH9AIwd9yyrwB3Vu/fCXy53nXWOJZVwOuAp082FpIrd24CssCS6vsa1nsMpzi2u4DbJlg3bWNbALyuer+F5ETC5dPhvTvB2KbFezf+lrYZei1XfpwOrgO+Vb3/LeBd9Suldu6+Dtg/bvHxxnId8KC7D7v7r0lOSjvh2cX1dJyxHU/axrbH3Z+s3j8MPEtycb3Uv3cnGNvxpGZsE0lboNd0VceUceCfzWyDmd1cXTbf3fdA8h8kMK9u1b18xxvLdHkvb61+qcv9Y1oSqR2bmV0IXAY8wTR778aNDabZewfpC/SaruqYMr/l7q8j+ZKQPzCzVfUu6CyZDu/l14GLgUuBPcCfVpencmxm1gx8F/iMux860aoTLJvS45tgbNPqvRuRtkCfdld1dPfd1Z/7gO+TfLx7aeQLQqo/99WvwpfteGNJ/Xvp7i+5e9ndK8Bfc+SjeerGZmYxSeA94O7fqy6eFu/dRGObTu/dWGkL9PXAUjNbYmYZYDXwcJ1rOm1m1mRmLSP3gbcDT5OM6abqajcB/1ifCifF8cbyMLDazLJmtoTk6wt/Xof6Ttu4b+W6nuS9g5SNzcwM+N/As+7+1TFPpf69O97Ypst7d4x675U91RvJVR23kux9/ny963mZY7mIZI/6JmDLyHiAOcC/Ac9Xf86ud601jufvST6+FklmOh870ViAz1ffx+eAq+td/2mM7W+AzcBTJEGwIKVjexNJW+EpYGP1ds10eO9OMLZp8d6Nv+nUfxGRaSJtLRcRETkOBbqIyDShQBcRmSYU6CIi04QCXURkmlCgi4hMEwp0EZFp4v8D5qlghVkzluMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['accuracy','val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.018715800327750352, 0.99538463]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(scaled_X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ready Model for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = len(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=12,activation='relu'))\n",
    "\n",
    "# Last layer for multi-class classification of 2 colors\n",
    "model.add(Dense(units=2,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6497 samples\n",
      "Epoch 1/277\n",
      "6497/6497 [==============================] - 0s 69us/sample - loss: 0.5443 - accuracy: 0.7530\n",
      "Epoch 2/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.3552 - accuracy: 0.8330\n",
      "Epoch 3/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.2028 - accuracy: 0.9614\n",
      "Epoch 4/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.1314 - accuracy: 0.9758\n",
      "Epoch 5/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0989 - accuracy: 0.9803\n",
      "Epoch 6/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0816 - accuracy: 0.9823\n",
      "Epoch 7/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0718 - accuracy: 0.9828\n",
      "Epoch 8/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0651 - accuracy: 0.9831\n",
      "Epoch 9/277\n",
      "6497/6497 [==============================] - ETA: 0s - loss: 0.0613 - accuracy: 0.98 - 0s 30us/sample - loss: 0.0608 - accuracy: 0.9852\n",
      "Epoch 10/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0571 - accuracy: 0.9855\n",
      "Epoch 11/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0545 - accuracy: 0.9863\n",
      "Epoch 12/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0525 - accuracy: 0.9866\n",
      "Epoch 13/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0508 - accuracy: 0.9875\n",
      "Epoch 14/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0495 - accuracy: 0.9880\n",
      "Epoch 15/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0483 - accuracy: 0.9875\n",
      "Epoch 16/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0472 - accuracy: 0.9885\n",
      "Epoch 17/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0465 - accuracy: 0.9885\n",
      "Epoch 18/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0457 - accuracy: 0.9888\n",
      "Epoch 19/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0453 - accuracy: 0.9891\n",
      "Epoch 20/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0445 - accuracy: 0.9891\n",
      "Epoch 21/277\n",
      "6497/6497 [==============================] - 0s 34us/sample - loss: 0.0437 - accuracy: 0.9895\n",
      "Epoch 22/277\n",
      "6497/6497 [==============================] - 0s 34us/sample - loss: 0.0436 - accuracy: 0.9892\n",
      "Epoch 23/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0428 - accuracy: 0.9898\n",
      "Epoch 24/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0423 - accuracy: 0.9894\n",
      "Epoch 25/277\n",
      "6497/6497 [==============================] - 0s 34us/sample - loss: 0.0423 - accuracy: 0.9905\n",
      "Epoch 26/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0416 - accuracy: 0.9901\n",
      "Epoch 27/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0413 - accuracy: 0.9897\n",
      "Epoch 28/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0407 - accuracy: 0.9908\n",
      "Epoch 29/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0407 - accuracy: 0.9901\n",
      "Epoch 30/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0400 - accuracy: 0.9909\n",
      "Epoch 31/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0403 - accuracy: 0.9905\n",
      "Epoch 32/277\n",
      "6497/6497 [==============================] - 0s 34us/sample - loss: 0.0398 - accuracy: 0.9905\n",
      "Epoch 33/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0394 - accuracy: 0.9911\n",
      "Epoch 34/277\n",
      "6497/6497 [==============================] - 0s 34us/sample - loss: 0.0394 - accuracy: 0.9914\n",
      "Epoch 35/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0388 - accuracy: 0.9911\n",
      "Epoch 36/277\n",
      "6497/6497 [==============================] - 0s 35us/sample - loss: 0.0387 - accuracy: 0.9906\n",
      "Epoch 37/277\n",
      "6497/6497 [==============================] - 0s 34us/sample - loss: 0.0387 - accuracy: 0.9903\n",
      "Epoch 38/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0380 - accuracy: 0.9908\n",
      "Epoch 39/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0378 - accuracy: 0.9917\n",
      "Epoch 40/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0372 - accuracy: 0.9906\n",
      "Epoch 41/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0368 - accuracy: 0.9911\n",
      "Epoch 42/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0367 - accuracy: 0.9912\n",
      "Epoch 43/277\n",
      "6497/6497 [==============================] - 0s 34us/sample - loss: 0.0362 - accuracy: 0.9911\n",
      "Epoch 44/277\n",
      "6497/6497 [==============================] - 0s 35us/sample - loss: 0.0360 - accuracy: 0.9906\n",
      "Epoch 45/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0357 - accuracy: 0.9917\n",
      "Epoch 46/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0353 - accuracy: 0.9917\n",
      "Epoch 47/277\n",
      "6497/6497 [==============================] - 0s 34us/sample - loss: 0.0353 - accuracy: 0.9918\n",
      "Epoch 48/277\n",
      "6497/6497 [==============================] - 0s 34us/sample - loss: 0.0349 - accuracy: 0.9922\n",
      "Epoch 49/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0350 - accuracy: 0.9918\n",
      "Epoch 50/277\n",
      "6497/6497 [==============================] - 0s 34us/sample - loss: 0.0345 - accuracy: 0.9922\n",
      "Epoch 51/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0344 - accuracy: 0.9912\n",
      "Epoch 52/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0339 - accuracy: 0.9925\n",
      "Epoch 53/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0336 - accuracy: 0.9925\n",
      "Epoch 54/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0333 - accuracy: 0.9926\n",
      "Epoch 55/277\n",
      "6497/6497 [==============================] - 0s 34us/sample - loss: 0.0332 - accuracy: 0.9917\n",
      "Epoch 56/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0332 - accuracy: 0.9922\n",
      "Epoch 57/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0326 - accuracy: 0.9929\n",
      "Epoch 58/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0324 - accuracy: 0.9923\n",
      "Epoch 59/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0324 - accuracy: 0.9925\n",
      "Epoch 60/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0329 - accuracy: 0.9928\n",
      "Epoch 61/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0315 - accuracy: 0.9937\n",
      "Epoch 62/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0317 - accuracy: 0.9929\n",
      "Epoch 63/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0315 - accuracy: 0.9917\n",
      "Epoch 64/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0309 - accuracy: 0.9925\n",
      "Epoch 65/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0308 - accuracy: 0.9928\n",
      "Epoch 66/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0305 - accuracy: 0.9932\n",
      "Epoch 67/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0305 - accuracy: 0.9929\n",
      "Epoch 68/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0303 - accuracy: 0.9926s - loss: 0.0260 - accuracy: \n",
      "Epoch 69/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0300 - accuracy: 0.9932\n",
      "Epoch 70/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0298 - accuracy: 0.9932\n",
      "Epoch 71/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0299 - accuracy: 0.9929\n",
      "Epoch 72/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0295 - accuracy: 0.9932\n",
      "Epoch 73/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0293 - accuracy: 0.9929\n",
      "Epoch 74/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0298 - accuracy: 0.9928\n",
      "Epoch 75/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0289 - accuracy: 0.9934\n",
      "Epoch 76/277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0287 - accuracy: 0.9937\n",
      "Epoch 77/277\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0290 - accuracy: 0.9929\n",
      "Epoch 78/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0284 - accuracy: 0.9937\n",
      "Epoch 79/277\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0281 - accuracy: 0.9937\n",
      "Epoch 80/277\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0281 - accuracy: 0.9935\n",
      "Epoch 81/277\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0280 - accuracy: 0.9932\n",
      "Epoch 82/277\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0277 - accuracy: 0.9938\n",
      "Epoch 83/277\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0279 - accuracy: 0.9935\n",
      "Epoch 84/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0274 - accuracy: 0.9942\n",
      "Epoch 85/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0271 - accuracy: 0.9942\n",
      "Epoch 86/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0271 - accuracy: 0.9938\n",
      "Epoch 87/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0269 - accuracy: 0.9938\n",
      "Epoch 88/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0266 - accuracy: 0.9943\n",
      "Epoch 89/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0267 - accuracy: 0.9940\n",
      "Epoch 90/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0264 - accuracy: 0.9937\n",
      "Epoch 91/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0263 - accuracy: 0.9943\n",
      "Epoch 92/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0259 - accuracy: 0.9942\n",
      "Epoch 93/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0260 - accuracy: 0.9945\n",
      "Epoch 94/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0256 - accuracy: 0.9943\n",
      "Epoch 95/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0257 - accuracy: 0.9945\n",
      "Epoch 96/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0255 - accuracy: 0.9948\n",
      "Epoch 97/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0252 - accuracy: 0.9943\n",
      "Epoch 98/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0251 - accuracy: 0.9942\n",
      "Epoch 99/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0252 - accuracy: 0.9943\n",
      "Epoch 100/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0247 - accuracy: 0.9946\n",
      "Epoch 101/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0246 - accuracy: 0.9943\n",
      "Epoch 102/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0245 - accuracy: 0.9945\n",
      "Epoch 103/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0244 - accuracy: 0.9945\n",
      "Epoch 104/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0245 - accuracy: 0.9942\n",
      "Epoch 105/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0244 - accuracy: 0.9949\n",
      "Epoch 106/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0240 - accuracy: 0.9949\n",
      "Epoch 107/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0241 - accuracy: 0.9945\n",
      "Epoch 108/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0233 - accuracy: 0.9948\n",
      "Epoch 109/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0237 - accuracy: 0.9948\n",
      "Epoch 110/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0235 - accuracy: 0.9951\n",
      "Epoch 111/277\n",
      "6497/6497 [==============================] - 0s 34us/sample - loss: 0.0236 - accuracy: 0.9948\n",
      "Epoch 112/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0231 - accuracy: 0.9951\n",
      "Epoch 113/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0227 - accuracy: 0.9948\n",
      "Epoch 114/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0231 - accuracy: 0.9951\n",
      "Epoch 115/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0230 - accuracy: 0.9946\n",
      "Epoch 116/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0228 - accuracy: 0.9946\n",
      "Epoch 117/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0224 - accuracy: 0.9952\n",
      "Epoch 118/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0224 - accuracy: 0.9952\n",
      "Epoch 119/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0223 - accuracy: 0.9951\n",
      "Epoch 120/277\n",
      "6497/6497 [==============================] - 0s 34us/sample - loss: 0.0225 - accuracy: 0.9949\n",
      "Epoch 121/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0220 - accuracy: 0.9948\n",
      "Epoch 122/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0220 - accuracy: 0.9951\n",
      "Epoch 123/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0220 - accuracy: 0.9952\n",
      "Epoch 124/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0218 - accuracy: 0.9952\n",
      "Epoch 125/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0216 - accuracy: 0.9951\n",
      "Epoch 126/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0217 - accuracy: 0.9949\n",
      "Epoch 127/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0217 - accuracy: 0.9952\n",
      "Epoch 128/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0215 - accuracy: 0.9949\n",
      "Epoch 129/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0214 - accuracy: 0.9952\n",
      "Epoch 130/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0213 - accuracy: 0.9951\n",
      "Epoch 131/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0211 - accuracy: 0.9951\n",
      "Epoch 132/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0210 - accuracy: 0.9951\n",
      "Epoch 133/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0208 - accuracy: 0.9957\n",
      "Epoch 134/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0209 - accuracy: 0.9951\n",
      "Epoch 135/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0208 - accuracy: 0.9952\n",
      "Epoch 136/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0205 - accuracy: 0.9955\n",
      "Epoch 137/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0207 - accuracy: 0.9957\n",
      "Epoch 138/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0206 - accuracy: 0.9957\n",
      "Epoch 139/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0203 - accuracy: 0.9955\n",
      "Epoch 140/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0203 - accuracy: 0.9957\n",
      "Epoch 141/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0201 - accuracy: 0.9958\n",
      "Epoch 142/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0201 - accuracy: 0.9955\n",
      "Epoch 143/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0202 - accuracy: 0.9958\n",
      "Epoch 144/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0199 - accuracy: 0.9955\n",
      "Epoch 145/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0199 - accuracy: 0.9960\n",
      "Epoch 146/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0198 - accuracy: 0.9960\n",
      "Epoch 147/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0198 - accuracy: 0.9957\n",
      "Epoch 148/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0198 - accuracy: 0.9960\n",
      "Epoch 149/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0198 - accuracy: 0.9955\n",
      "Epoch 150/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0193 - accuracy: 0.9957\n",
      "Epoch 151/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0193 - accuracy: 0.9960\n",
      "Epoch 152/277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0195 - accuracy: 0.9960\n",
      "Epoch 153/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0194 - accuracy: 0.9960\n",
      "Epoch 154/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0193 - accuracy: 0.9960\n",
      "Epoch 155/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0189 - accuracy: 0.9960\n",
      "Epoch 156/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0192 - accuracy: 0.9962\n",
      "Epoch 157/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0189 - accuracy: 0.9960\n",
      "Epoch 158/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0188 - accuracy: 0.9962\n",
      "Epoch 159/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0189 - accuracy: 0.9958\n",
      "Epoch 160/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0190 - accuracy: 0.9963\n",
      "Epoch 161/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0188 - accuracy: 0.9958\n",
      "Epoch 162/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0187 - accuracy: 0.9960\n",
      "Epoch 163/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0187 - accuracy: 0.9962\n",
      "Epoch 164/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0186 - accuracy: 0.9960\n",
      "Epoch 165/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0189 - accuracy: 0.9958\n",
      "Epoch 166/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0186 - accuracy: 0.9958\n",
      "Epoch 167/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0184 - accuracy: 0.9963\n",
      "Epoch 168/277\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0183 - accuracy: 0.9962\n",
      "Epoch 169/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0184 - accuracy: 0.9962\n",
      "Epoch 170/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0183 - accuracy: 0.9962\n",
      "Epoch 171/277\n",
      "6497/6497 [==============================] - 0s 33us/sample - loss: 0.0182 - accuracy: 0.9960\n",
      "Epoch 172/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0182 - accuracy: 0.9960\n",
      "Epoch 173/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0180 - accuracy: 0.9963\n",
      "Epoch 174/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0182 - accuracy: 0.9960\n",
      "Epoch 175/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0184 - accuracy: 0.9962\n",
      "Epoch 176/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0178 - accuracy: 0.9960\n",
      "Epoch 177/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0183 - accuracy: 0.9962\n",
      "Epoch 178/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0180 - accuracy: 0.9960\n",
      "Epoch 179/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0176 - accuracy: 0.9963\n",
      "Epoch 180/277\n",
      "6497/6497 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.99 - 0s 29us/sample - loss: 0.0176 - accuracy: 0.9963\n",
      "Epoch 181/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0176 - accuracy: 0.9965\n",
      "Epoch 182/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0176 - accuracy: 0.9963\n",
      "Epoch 183/277\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0175 - accuracy: 0.9962\n",
      "Epoch 184/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0178 - accuracy: 0.9962\n",
      "Epoch 185/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0205 - accuracy: 0.9962\n",
      "Epoch 186/277\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0173 - accuracy: 0.9962\n",
      "Epoch 187/277\n",
      "6497/6497 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.99 - 0s 29us/sample - loss: 0.0173 - accuracy: 0.9960\n",
      "Epoch 188/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0173 - accuracy: 0.9962\n",
      "Epoch 189/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0173 - accuracy: 0.9963\n",
      "Epoch 190/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0172 - accuracy: 0.9962\n",
      "Epoch 191/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0171 - accuracy: 0.9962\n",
      "Epoch 192/277\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0172 - accuracy: 0.9962\n",
      "Epoch 193/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0173 - accuracy: 0.9962\n",
      "Epoch 194/277\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0171 - accuracy: 0.9962\n",
      "Epoch 195/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0172 - accuracy: 0.9963\n",
      "Epoch 196/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0172 - accuracy: 0.9962\n",
      "Epoch 197/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0172 - accuracy: 0.9962\n",
      "Epoch 198/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0170 - accuracy: 0.9962\n",
      "Epoch 199/277\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0170 - accuracy: 0.9963\n",
      "Epoch 200/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0172 - accuracy: 0.9963\n",
      "Epoch 201/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0168 - accuracy: 0.9962\n",
      "Epoch 202/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0168 - accuracy: 0.9963\n",
      "Epoch 203/277\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0170 - accuracy: 0.9962\n",
      "Epoch 204/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0169 - accuracy: 0.9960\n",
      "Epoch 205/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0172 - accuracy: 0.9963\n",
      "Epoch 206/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0168 - accuracy: 0.9962\n",
      "Epoch 207/277\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0170 - accuracy: 0.9960\n",
      "Epoch 208/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0169 - accuracy: 0.9963\n",
      "Epoch 209/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0168 - accuracy: 0.9962\n",
      "Epoch 210/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0168 - accuracy: 0.9963\n",
      "Epoch 211/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0168 - accuracy: 0.9962\n",
      "Epoch 212/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0169 - accuracy: 0.9962\n",
      "Epoch 213/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0167 - accuracy: 0.9963\n",
      "Epoch 214/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0165 - accuracy: 0.9962\n",
      "Epoch 215/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0166 - accuracy: 0.9963\n",
      "Epoch 216/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0162 - accuracy: 0.9965\n",
      "Epoch 217/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0169 - accuracy: 0.9962\n",
      "Epoch 218/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0167 - accuracy: 0.9962\n",
      "Epoch 219/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0167 - accuracy: 0.9962\n",
      "Epoch 220/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0164 - accuracy: 0.9962\n",
      "Epoch 221/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0162 - accuracy: 0.9963\n",
      "Epoch 222/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0160 - accuracy: 0.9962\n",
      "Epoch 223/277\n",
      "6497/6497 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.99 - 0s 29us/sample - loss: 0.0168 - accuracy: 0.9963\n",
      "Epoch 224/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0164 - accuracy: 0.9965\n",
      "Epoch 225/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0165 - accuracy: 0.9963\n",
      "Epoch 226/277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0164 - accuracy: 0.9962\n",
      "Epoch 227/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0161 - accuracy: 0.9962s - loss: 0.0110 - accuracy: \n",
      "Epoch 228/277\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0164 - accuracy: 0.9962\n",
      "Epoch 229/277\n",
      "6497/6497 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.99 - 0s 29us/sample - loss: 0.0161 - accuracy: 0.9962\n",
      "Epoch 230/277\n",
      "6497/6497 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.99 - 0s 28us/sample - loss: 0.0164 - accuracy: 0.9963\n",
      "Epoch 231/277\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0161 - accuracy: 0.9962\n",
      "Epoch 232/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0165 - accuracy: 0.9963\n",
      "Epoch 233/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0161 - accuracy: 0.9963\n",
      "Epoch 234/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0160 - accuracy: 0.9962\n",
      "Epoch 235/277\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0159 - accuracy: 0.9962\n",
      "Epoch 236/277\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0163 - accuracy: 0.9965\n",
      "Epoch 237/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0159 - accuracy: 0.9963\n",
      "Epoch 238/277\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0159 - accuracy: 0.9963\n",
      "Epoch 239/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0161 - accuracy: 0.9962\n",
      "Epoch 240/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0162 - accuracy: 0.9962s - loss: 0.0174 - accuracy: \n",
      "Epoch 241/277\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0163 - accuracy: 0.9962\n",
      "Epoch 242/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0162 - accuracy: 0.9963\n",
      "Epoch 243/277\n",
      "6497/6497 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.99 - 0s 29us/sample - loss: 0.0160 - accuracy: 0.9963\n",
      "Epoch 244/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0159 - accuracy: 0.9960\n",
      "Epoch 245/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0153 - accuracy: 0.9965\n",
      "Epoch 246/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0162 - accuracy: 0.9962\n",
      "Epoch 247/277\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0155 - accuracy: 0.9963\n",
      "Epoch 248/277\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0163 - accuracy: 0.9963\n",
      "Epoch 249/277\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0157 - accuracy: 0.9963\n",
      "Epoch 250/277\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0157 - accuracy: 0.9962\n",
      "Epoch 251/277\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0156 - accuracy: 0.9963\n",
      "Epoch 252/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0159 - accuracy: 0.9962\n",
      "Epoch 253/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0157 - accuracy: 0.9963\n",
      "Epoch 254/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0159 - accuracy: 0.9962\n",
      "Epoch 255/277\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0158 - accuracy: 0.9963\n",
      "Epoch 256/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0159 - accuracy: 0.9960\n",
      "Epoch 257/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0156 - accuracy: 0.9963\n",
      "Epoch 258/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0157 - accuracy: 0.9960\n",
      "Epoch 259/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0155 - accuracy: 0.9963\n",
      "Epoch 260/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0154 - accuracy: 0.9963\n",
      "Epoch 261/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0158 - accuracy: 0.9960\n",
      "Epoch 262/277\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0156 - accuracy: 0.9963\n",
      "Epoch 263/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0155 - accuracy: 0.9962\n",
      "Epoch 264/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0155 - accuracy: 0.9962s - loss: 0.0175 - accuracy: 0.99\n",
      "Epoch 265/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0155 - accuracy: 0.9962\n",
      "Epoch 266/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0156 - accuracy: 0.9963\n",
      "Epoch 267/277\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0153 - accuracy: 0.9966\n",
      "Epoch 268/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0158 - accuracy: 0.9962\n",
      "Epoch 269/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0154 - accuracy: 0.9965\n",
      "Epoch 270/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0155 - accuracy: 0.9963\n",
      "Epoch 271/277\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0153 - accuracy: 0.9963\n",
      "Epoch 272/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0153 - accuracy: 0.9963\n",
      "Epoch 273/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0155 - accuracy: 0.9962\n",
      "Epoch 274/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0152 - accuracy: 0.9963\n",
      "Epoch 275/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0154 - accuracy: 0.9960s - loss: 0.0122 - accuracy: 0.\n",
      "Epoch 276/277\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0154 - accuracy: 0.9965\n",
      "Epoch 277/277\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0153 - accuracy: 0.9965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fe67ff8d68>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X,y,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"final_wine_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wine_scaler.pkl']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler,'wine_scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting a Single New Wine Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "wine_model = load_model(\"final_wine_model.h5\")\n",
    "wine_scaler = joblib.load(\"wine_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density   pH  sulphates  \\\n",
       "0                 45.0                 170.0    1.001  3.0       0.45   \n",
       "\n",
       "   alcohol  quality  color  \n",
       "0      8.8        6  white  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_example = {'fixed_acidity':7.2,\n",
    "                 'volatile_acidity':0.66,\n",
    "                 'citric_acid':0.33,\n",
    "                 'residual_sugar':2.5,\n",
    "                 'chlorides':0.068,\n",
    "                 'free_sulfur_dioxide':34.0,\n",
    "                 'total_sulfur_dioxide':102.0,\n",
    "                 'density':0.99,\n",
    "                 'pH':3.27,\n",
    "                 'sulphates':0.78,\n",
    "                 'alcohol':12.8,\n",
    "                 'quality':6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar', 'chlorides', 'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_example.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['red', 'white'], dtype='<U5')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_prediction(model,scaler,sample_json):\n",
    "    \n",
    "    # For larger data features, you should probably write a for loop\n",
    "    # That builds out this array for you\n",
    "    \n",
    "    f_a = sample_json['fixed_acidity']\n",
    "    v_a = sample_json['volatile_acidity']\n",
    "    c_a = sample_json['citric_acid']\n",
    "    r_s = sample_json['residual_sugar']\n",
    "    chl = sample_json['chlorides']\n",
    "    f_s_d = sample_json['free_sulfur_dioxide']\n",
    "    t_s_d = sample_json['total_sulfur_dioxide']\n",
    "    den = sample_json['density']\n",
    "    ph = sample_json['pH']\n",
    "    sul = sample_json['sulphates']\n",
    "    alc = sample_json['alcohol']\n",
    "    qua = sample_json['quality']\n",
    "    \n",
    "    wine = [[f_a,v_a,c_a,r_s,chl,f_s_d,t_s_d,den,ph,sul,alc,qua]]\n",
    "    \n",
    "    wine = scaler.transform(wine)\n",
    "    \n",
    "    classes = np.array(['red', 'white'])\n",
    "    \n",
    "    class_ind = model.predict_classes(wine)\n",
    "    \n",
    "    return classes[class_ind][0]\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'white'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_prediction(wine_model,wine_scaler,wine_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE FOR DEPLOYMENT: START HERE! 5/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "\n",
    "wine_model = load_model(\"final_wine_model.h5\")\n",
    "wine_scaler = joblib.load(\"wine_scaler.pkl\")\n",
    "\n",
    "\n",
    "def return_prediction(model,scaler,sample_json):\n",
    "    \n",
    "    # For larger data features, you should probably write a for loop\n",
    "    # That builds out this array for you\n",
    "    f_a = sample_json['fixed_acidity']\n",
    "    v_a = sample_json['volatile_acidity']\n",
    "    c_a = sample_json['citric_acid']\n",
    "    r_s = sample_json['residual_sugar']\n",
    "    chl = sample_json['chlorides']\n",
    "    f_s_d = sample_json['free_sulfur_dioxide']\n",
    "    t_s_d = sample_json['total_sulfur_dioxide']\n",
    "    den = sample_json['density']\n",
    "    ph = sample_json['pH']\n",
    "    sul = sample_json['sulphates']\n",
    "    alc = sample_json['alcohol']\n",
    "    qua = sample_json['quality']\n",
    "    \n",
    "    wine = [[f_a,v_a,c_a,r_s,chl,f_s_d,t_s_d,den,ph,sul,alc,qua]]\n",
    "    \n",
    "    wine = scaler.transform(wine)\n",
    "    \n",
    "    classes = np.array(['red', 'white'])\n",
    "    \n",
    "    class_ind = model.predict_classes(wine)\n",
    "    \n",
    "    return classes[class_ind][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_example = {\n",
    "    \"fixed_acidity\":7.2,\n",
    "    \"volatile_acidity\":0.66,\n",
    "    \"citric_acid\":0.33,\n",
    "    \"residual_sugar\":2.5,\n",
    "    \"chlorides\":0.068,\n",
    "    \"free_sulfur_dioxide\":34.0,\n",
    "    \"total_sulfur_dioxide\":102.0,\n",
    "    \"density\":0.99,\n",
    "    \"pH\":3.27,\n",
    "    \"sulphates\":0.78,\n",
    "    \"alcohol\":12.8,\n",
    "    \"quality\":6\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonAdv]",
   "language": "python",
   "name": "conda-env-PythonAdv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
